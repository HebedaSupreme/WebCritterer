# WebCritterer

## Specifications

-Given a seed URL, the crawler will go to the specified page.
-Have a large, but existent limit on the number of pages the bot can travel across
-Having reached the page, it will take all the other links on the page and add them onto a list of URLS to visit.
-It will archive them into queue, prioritized. <â€”maybe not for now
-It will collect the text from the page and download as text files per page
-Crawler will avoid following links it has already taken

## Getting Started

...

### Prerequisites

...

```
...
```

### Installing

...
...

```
...
```

...

```
...
```
...


## Deployment

...

## Built With

...

## Contributing

Please read [CONTRIBUTING.md](https://gist.github.com/PurpleBooth/b24679402957c63ec426) for details on our code of conduct, and the process for submitting pull requests to us.

## Authors

* **Michael Li** - *Initial work* -

See also the list of [contributors]

## License

...

## Acknowledgments

* Hat tip to anyone whose code was used
* Inspiration
* etc

